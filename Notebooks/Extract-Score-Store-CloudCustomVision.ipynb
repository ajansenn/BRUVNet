{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract, Score and Store - Local Videos & CustomVision.ai Model\n",
    "\n",
    "This notebook will extract images from video, score against a CustomVision.ai model endpoint to filter images without fish present and store in an Azure Blob Container.\n",
    "\n",
    "Requirements:\n",
    "* Videos in .mp4 format stored locally on your computer drive\n",
    "* A CustomVision.ai model trained to identify fish species (Iteration Published)\n",
    "* An Azure Storage account to store scored frames in\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import cv2, io, json, logging, os, sys, tempfile,uuid\n",
    "import numpy as np\n",
    "import xlsxwriter \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from azure.cognitiveservices.vision.customvision.training.models import ImageFileCreateEntry, Region\n",
    "from azure.cognitiveservices.vision.customvision.prediction import CustomVisionPredictionClient\n",
    "from matplotlib.patches import Rectangle\n",
    "from datetime import datetime, timedelta\n",
    "from azure.storage.blob import ResourceTypes, AccountSasPermissions, AccessPolicy, ContainerSasPermissions,generate_container_sas,BlobServiceClient, BlobClient, ContainerClient\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CustomVision.ai Credentials\n",
    "\n",
    "Provide the access details to your customvision project and model that will be used to filter the images for YesFish/NoFish. Indicate the file path locally on your desktop where videos are stored then enter the Azure storage account connection string to store all the filtered images. \n",
    "\n",
    "The dictionary can be adjusted for your classes to allow class-specific thresholding i.e. only include predictions >50% confidence. This is included as some classes perform better than others, and to avoid increased number of false positives, an adjustable thresholding systems ensures more accurate filtering. The class Average Precision values can be used as a guide for threshold values. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# endpoint for the customvision cognitive servies account training e.g. https://myaccount.cognitiveservices.azure.com/\n",
    "endpoint = \"\"\n",
    "\n",
    "# Replace with a valid key \n",
    "prediction_key = \"\" # Key found in the prediction URL from CustomVision Performance Page\n",
    "projectID = \"\" # Found in the CustomVision project settings page\n",
    "\n",
    "# Replace with a valid iteration \n",
    "iteration = \"Iteration1\" #name of iteration, must match same iteration prediction key is being used\n",
    "\n",
    "# Replace with a valid file path \n",
    "path = \"C:\\\\  \\  \\\"\n",
    "# Storage connection string format \"DefaultEndpointsProtocol=https;AccountName=audiostores2tg********\"\n",
    "connect_str = \"DefaultEndpointsProtocol=htt*****\"\n",
    "\n",
    "# dictionary list for thresholding values from Custom Vision\n",
    "thresholding_values = {\n",
    "    \"Ambassis agrammus\":50 ,\n",
    "    \"Ambassis macleayi\":50 ,\n",
    "    \"Amniataba percoides\":50 ,\n",
    "    \"Craterocephalus sturcusmuscarum\":50,\n",
    "    \"Denariusa bandata\":50,\n",
    "    \"Glossamia aprion\":50,\n",
    "    \"Lates calcarifer\":50 ,\n",
    "    \"Melanotaenia nigrans\":50 ,\n",
    "    \"Melanotaenia splendida inornata\":50,\n",
    "    \"Neoarius\":50,\n",
    "    \"Neosilurus\":50,\n",
    "    \"Other\":50,\n",
    "    \"Scleropages jardinii\":50,\n",
    "    \"Strongylura krefftii\":50,\n",
    "    \"Sycomistes butleri\":50,\n",
    "    \"Toxotes chatareus\":50 \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_info(file_path):\n",
    "\n",
    "    file_info = {}\n",
    "\n",
    "    parts = file_path.split(os.sep)\n",
    "\n",
    "    file_info['video_name'] = os.path.splitext(parts[-1])[0]\n",
    "    file_info['location_name'] = parts[-2]\n",
    "    file_info['transect_name'] = parts[-3]\n",
    "    file_info['site_name'] = parts[-4]\n",
    "    file_info['billabong_type'] = parts[-5]\n",
    "    file_info['year'] = parts[-6]\n",
    "\n",
    "    return file_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_azure_storage_container(container_name):\n",
    "\n",
    "    container = ContainerClient.from_connection_string(connect_str, container_name)\n",
    "\n",
    "    try:\n",
    "        container_properties = container.get_container_properties()\n",
    "        container_client = blob_service_client.get_container_client(container_name)\n",
    "        # Container exists. You can now use it.\n",
    "        print(f\"Container {container_name} already exists.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        # Container does not exist. You can now create it.\n",
    "        container_client = blob_service_client.create_container(container_name)\n",
    "        #print(e)\n",
    "        print(f\"Creating container {container_name}.\")\n",
    "\n",
    "    return container_client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_container_sastoken(container_client):\n",
    "\n",
    "    sas_token = generate_container_sas(\n",
    "        container_client.account_name,\n",
    "        container_client.container_name,\n",
    "        account_key=container_client.credential.account_key,    \n",
    "        permission=ContainerSasPermissions(read=True),\n",
    "        expiry=datetime.utcnow() + timedelta(hours=730),\n",
    "    )\n",
    "    print('SAS token for the storage container ?{0}'.format(sas_token))\n",
    "\n",
    "    return sas_token\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_show_predictions(results, np_image, frame_count, fps, min_probability, debug=False):\n",
    "    species_counter = {}\n",
    "    for prediction in results.predictions:\n",
    "\n",
    "        if prediction.tag_name not in thresholding_values:\n",
    "            print (\"WARNING: The Species name is not in threshold dictionary, probability is set to default\")\n",
    "            probability = min_probability\n",
    "        else:\n",
    "            probability = thresholding_values[prediction.tag_name]\n",
    "\n",
    "        if (prediction.probability*100) > probability:\n",
    "\n",
    "            if prediction.tag_name not in species_counter:\n",
    "                species_counter[prediction.tag_name] = [{'time':round(frame_count/fps,3), 'probability':round(prediction.probability*100,2)}]\n",
    "            else:\n",
    "                species_counter[prediction.tag_name].append({'time':round(frame_count/fps,3), 'probability':round(prediction.probability*100,2)})\n",
    "    return species_counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjust Starting Time\n",
    "\n",
    "To adjust the starting time for frame extraction from your video change starting_time = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_vision_predictor(blob_service_client, file_path, prediction_key, endpoint, projectID,thresholding_values, iteration, predictions_per_sec=1, min_probability=50, debug=False):\n",
    "    # Getting parameters from the path\n",
    "    predictor = CustomVisionPredictionClient(prediction_key, endpoint=endpoint)\n",
    "    file_info = get_file_info(file_path)\n",
    "\n",
    "    # Create azure storage container\n",
    "    container_name = f\"{file_info['year']}-{file_info['site_name']}-{file_info['transect_name']}-{file_info['location_name']}-{file_info['video_name']}\".lower().replace(' ', '')\n",
    "    container_client = create_azure_storage_container(container_name)\n",
    "    sas_token = generate_container_sastoken(container_client)\n",
    "\n",
    "    container_name_NoFish = 'nofish'\n",
    "    noFishcontainer_client = create_azure_storage_container(container_name_NoFish)\n",
    "    nofish_container_file_path = f\"{file_info['year']}-{file_info['site_name']}-{file_info['transect_name']}-{file_info['video_name']}\"\n",
    "\n",
    "    # Split video into frames\n",
    "    video_dir = os.path.join(file_info['year'], file_info['billabong_type'], file_info['site_name'], file_info['transect_name'],file_info['location_name']).replace(os.sep, '-').replace(' ', '-')\n",
    "\n",
    "    starting_time = 0 # Seconds...\n",
    "\n",
    "    video_capture = cv2.VideoCapture(file_path)\n",
    "\n",
    "    num_of_frames = video_capture.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "\n",
    "    fps = int(video_capture.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "    if debug:\n",
    "        print(f\"Frames per second: {fps}\")\n",
    "        print(f\"Total frame count: {video_capture.get(cv2.CAP_PROP_FRAME_COUNT)}\")\n",
    "\n",
    "    frame_count = int(starting_time * fps)\n",
    "\n",
    "    video_capture.set(cv2.CAP_PROP_POS_FRAMES, frame_count)\n",
    "\n",
    "    error_frame_count = 0\n",
    "\n",
    "    # Analyse video frames and ran custom vision \n",
    "    while video_capture.isOpened():\n",
    "        success, np_image = video_capture.read()\n",
    "\n",
    "        if (frame_count % (fps//predictions_per_sec)) == 0:\n",
    "            if success is False:\n",
    "                print(f'Could not process frame: {frame_count} of {num_of_frames}')\n",
    "                error_frame_count += 1\n",
    "                frame_count += 1\n",
    "\n",
    "                if frame_count == num_of_frames:\n",
    "                    break\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "            frame_name = '{0}_Frame-{1}.jpg'.format(video_dir, frame_count)\n",
    "\n",
    "            np_image = cv2.cvtColor(np_image, cv2.COLOR_BGR2RGB)\n",
    "            buffer = io.BytesIO()\n",
    "            Image.fromarray(np_image).save(buffer, format='JPEG')\n",
    "            results = predictor.detect_image(projectID, iteration, buffer.getvalue())\n",
    "\n",
    "            species_counter = compute_show_predictions(results,np_image,frame_count,fps,min_probability,debug)\n",
    "\n",
    "            if species_counter:\n",
    "                blob_client = blob_service_client.get_blob_client(container=container_name, blob=frame_name)\n",
    "                blob_client.upload_blob(buffer.getvalue())\n",
    "                if debug:\n",
    "                    print('Uploading to fish container {0}...'.format(frame_name))\n",
    "\n",
    "            else:\n",
    "                if debug:\n",
    "                    print('Uploading to nofish container {0}...'.format(frame_name))\n",
    "                blob_client = blob_service_client.get_blob_client(container=container_name_NoFish , blob=nofish_container_file_path+'/' + frame_name)\n",
    "                blob_client.upload_blob(buffer.getvalue())\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "        if frame_count == num_of_frames:\n",
    "            break\n",
    "\n",
    "    video_capture.release()\n",
    "    print(f\"Total video frames:{num_of_frames}\")\n",
    "    print(f\"Total frames to process: {num_of_frames/fps}\")\n",
    "    print(f\"Total processed frames that errored: {error_frame_count}\")\n",
    "    # print(f'Total number of unprocessed frames: {error_frame_count} of {num_of_frames/fps}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "files = os.listdir(path)\n",
    "\n",
    "for f in files:\n",
    "    if os.path.splitext(f)[1] == '.mp4':\n",
    "\n",
    "        # Create the BlobServiceClient object which will be used to create a container client\n",
    "        blob_service_client = BlobServiceClient.from_connection_string(connect_str)\n",
    "        file_path = path + '\\\\' + f\n",
    "\n",
    "        #If no species found in the dictionary, min probability is set to 15 \n",
    "        custom_vision_predictor(blob_service_client,file_path, prediction_key, endpoint, projectID, thresholding_values, iteration, predictions_per_sec=1, min_probability=15, debug=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python (KakaduFishAI)",
   "language": "python",
   "name": "kakadufishai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
